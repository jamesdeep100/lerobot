#!/usr/bin/env python
"""
ACT è®­ç»ƒ Demo - PushT æ•°æ®é›†
============================
åŸºäºå®˜æ–¹ act_training_example.py å®šåˆ¶ï¼Œé€‚é… RTX 5090

ç”¨æ³•:
    conda activate lerobot
    cd /home/james/ai_projects/lerobot
    python examples/tutorial/act/act_training_pusht.py

ä½œè€…: James (å­¦ä¹ ç¬”è®°)
æ—¥æœŸ: 2026-01-06
"""

from pathlib import Path
import time

import torch

from lerobot.configs.types import FeatureType, PolicyFeature
from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata
from lerobot.datasets.utils import dataset_to_policy_features
from lerobot.policies.act.configuration_act import ACTConfig
from lerobot.policies.act.modeling_act import ACTPolicy
from lerobot.policies.factory import make_pre_post_processors


def make_delta_timestamps(delta_indices: list[int] | None, fps: int) -> list[float]:
    """å°†å¸§ç´¢å¼•è½¬æ¢ä¸ºæ—¶é—´æˆ³åç§»"""
    if delta_indices is None:
        return [0]
    return [i / fps for i in delta_indices]


def print_model_architecture(policy):
    """æ‰“å° ACT ç½‘ç»œç»“æ„ ASCII å›¾"""
    
    def count_params(module):
        return sum(p.numel() for p in module.parameters())
    
    def format_params(n):
        if n >= 1e9:
            return f"{n/1e9:.3f}B"
        elif n >= 1e6:
            return f"{n/1e6:.2f}M"
        elif n >= 1e3:
            return f"{n/1e3:.1f}K"
        else:
            return str(n)
    
    model = policy.model
    
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ACT ç½‘ç»œç»“æ„ (Action Chunking Transformer)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      è¾“å…¥ (Inputs)                                â”‚   â”‚
â”‚  â”‚  observation.image: [B, 3, 96, 96]    observation.state: [B, 2]  â”‚   â”‚
â”‚  â”‚  action (è®­ç»ƒç›®æ ‡): [B, chunk_size, 2]                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                â”‚                           â”‚
â”‚                            â–¼                â–¼                           â”‚""")
    
    backbone_params = count_params(model.backbone)
    vae_params = count_params(model.vae_encoder) + 512 + 1536 + 1536 + 32832
    
    print(f"""â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Vision Backbone       â”‚    â”‚   VAE Encoder (è®­ç»ƒæ—¶)          â”‚   â”‚
â”‚  â”‚   ResNet-18             â”‚    â”‚   4-layer Transformer           â”‚   â”‚
â”‚  â”‚   {format_params(backbone_params):>8}              â”‚    â”‚   {format_params(vae_params):>8}                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚                                   â”‚                       â”‚
â”‚            â”‚ Visual Tokens                     â”‚ Latent z (dim=32)     â”‚
â”‚            â–¼                                   â–¼                       â”‚""")
    
    encoder_params = count_params(model.encoder)
    
    print(f"""â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Transformer Encoder                            â”‚   â”‚
â”‚  â”‚   4-layer, dim=512, heads=8, ffn=3200                            â”‚   â”‚
â”‚  â”‚   è¾“å…¥: [Latent_z, Robot_State, Visual_Tokens]                    â”‚   â”‚
â”‚  â”‚   {format_params(encoder_params):>8}                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                    â”‚
â”‚                                    â”‚ Memory (èåˆç‰¹å¾)                   â”‚
â”‚                                    â–¼                                    â”‚""")
    
    decoder_params = count_params(model.decoder)
    
    print(f"""â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Transformer Decoder                            â”‚   â”‚
â”‚  â”‚   1-layer, Cross-Attention                                       â”‚   â”‚
â”‚  â”‚   Query: Positional Embeddings (chunk_size=100)                  â”‚   â”‚
â”‚  â”‚   {format_params(decoder_params):>8}                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                    â”‚
â”‚                                    â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      Action Head (Linear)                         â”‚   â”‚
â”‚  â”‚   è¾“å‡º: [B, chunk_size, action_dim]  â†’  [B, chunk_size, action_dim]              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ç»„ä»¶å‚æ•°ç»Ÿè®¡:                                                           â”‚""")
    
    print(f"""â”‚    â”œâ”€ Vision Backbone (ResNet-18):     {format_params(backbone_params):>10}                     â”‚
â”‚    â”œâ”€ VAE Encoder (4-layer Trans):     {format_params(vae_params):>10}                     â”‚
â”‚    â”œâ”€ Transformer Encoder (4-layer):   {format_params(encoder_params):>10}                     â”‚
â”‚    â”œâ”€ Transformer Decoder (1-layer):   {format_params(decoder_params):>10}                     â”‚
â”‚    â””â”€ å…¶ä»– (Projections, Embeds):      {format_params(count_params(policy) - backbone_params - vae_params - encoder_params - decoder_params):>10}                     â”‚
â”‚                                                                         â”‚
â”‚  æ€»è®¡: {format_params(count_params(policy)):>10} ({count_params(policy)/1e9:.4f}B)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")


def main():
    # ============================================================
    # é…ç½®åŒº - å¯è‡ªå®šä¹‰ä¿®æ”¹
    # ============================================================
    
    # æ•°æ®é›†é€‰æ‹©ï¼ˆpusht æ˜¯æœ€å°çš„ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•ï¼‰
    dataset_id = "lerobot/pusht"
    
    # è¾“å‡ºç›®å½•
    output_directory = Path("outputs/act_pusht_demo")
    output_directory.mkdir(parents=True, exist_ok=True)
    
    # è®¾å¤‡é€‰æ‹©ï¼ˆRTX 5090 ç”¨ cudaï¼‰
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    if device.type == "cuda":
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # è®­ç»ƒå‚æ•°
    training_steps = 5000       # è®­ç»ƒæ­¥æ•°
    batch_size = 32             # æ‰¹å¤§å°
    log_freq = 10              # æ—¥å¿—é¢‘ç‡
    
    # ============================================================
    # æ¨¡å‹é…ç½® - å¯è‡ªå®šä¹‰æ¶æ„
    # ============================================================
    
    # 1. è·å–æ•°æ®é›†å…ƒæ•°æ®ï¼ˆåªä¸‹è½½å‡  MBï¼‰
    print(f"\nğŸ“¦ åŠ è½½æ•°æ®é›†å…ƒæ•°æ®: {dataset_id}")
    dataset_metadata = LeRobotDatasetMetadata(dataset_id)
    print(f"   FPS: {dataset_metadata.fps}")
    print(f"   Episodes: {dataset_metadata.total_episodes}")
    print(f"   Frames: {dataset_metadata.total_frames}")
    
    # 2. è‡ªåŠ¨æå–ç‰¹å¾ï¼ˆä¹Ÿå¯ä»¥æ‰‹åŠ¨æŒ‡å®šï¼Œè§ä¸‹æ–¹æ³¨é‡Šï¼‰
    features = dataset_to_policy_features(dataset_metadata.features)
    output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}
    input_features = {key: ft for key, ft in features.items() if key not in output_features}
    
    print(f"\nğŸ“Š ç‰¹å¾é…ç½®:")
    print(f"   è¾“å…¥ç‰¹å¾: {list(input_features.keys())}")
    print(f"   è¾“å‡ºç‰¹å¾: {list(output_features.keys())}")
    
    # ã€å¯é€‰ã€‘æ‰‹åŠ¨æŒ‡å®šç‰¹å¾ï¼ˆå®Œå…¨æ§åˆ¶æ¨¡å¼ï¼‰
    # input_features = {
    #     "observation.state": PolicyFeature(type=FeatureType.STATE, shape=(2,)),
    # }
    # output_features = {
    #     "action": PolicyFeature(type=FeatureType.ACTION, shape=(2,)),
    # }
    
    # 3. åˆ›å»º ACT é…ç½®ï¼ˆå¯è‡ªå®šä¹‰æ¶æ„å‚æ•°ï¼‰
    cfg = ACTConfig(
        input_features=input_features,
        output_features=output_features,
        # ---- æ¶æ„å‚æ•°ï¼ˆå¯è°ƒæ•´ï¼‰----
        chunk_size=10,              # Action Chunking å¤§å°ï¼ˆæœ€ä¼˜å€¼ï¼‰
        n_action_steps=10,          # æ¯æ¬¡æ‰§è¡Œçš„åŠ¨ä½œæ­¥æ•°
        dim_model=512,               # Transformer éšè—ç»´åº¦
        n_heads=8,                   # æ³¨æ„åŠ›å¤´æ•°
        n_encoder_layers=4,          # Encoder å±‚æ•°
        n_decoder_layers=1,          # Decoder å±‚æ•°
        use_vae=True,                # æ˜¯å¦ä½¿ç”¨ VAE
        latent_dim=32,               # VAE éšå˜é‡ç»´åº¦
        vision_backbone="resnet18",   # è§†è§‰éª¨å¹²ï¼ˆpusht æœ‰ 96x96 RGB å›¾åƒï¼‰
        # ---- ä¼˜åŒ–å™¨å‚æ•° ----
        optimizer_lr=1e-5,           # å­¦ä¹ ç‡ï¼ˆé»˜è®¤å€¼ï¼‰
        optimizer_lr_backbone=1e-5,  # backbone å­¦ä¹ ç‡
    )
    
    # ============================================================
    # æ¨¡å‹åˆ›å»º
    # ============================================================
    
    print(f"\nğŸ¤– åˆ›å»º ACT æ¨¡å‹...")
    policy = ACTPolicy(cfg)
    preprocessor, postprocessor = make_pre_post_processors(cfg, dataset_stats=dataset_metadata.stats)
    
    # ç»Ÿè®¡å‚æ•°é‡ï¼ˆç”¨ B ä½œä¸ºå•ä½ï¼Œæ–¹ä¾¿ä¸å¤§æ¨¡å‹å¯¹æ¯”ï¼‰
    total_params = sum(p.numel() for p in policy.parameters())
    trainable_params = sum(p.numel() for p in policy.parameters() if p.requires_grad)
    print(f"   æ€»å‚æ•°: {total_params:,} ({total_params / 1e9:.4f}B)")
    print(f"   å¯è®­ç»ƒ: {trainable_params:,} ({trainable_params / 1e9:.4f}B)")
    
    # æ‰“å°ç½‘ç»œç»“æ„æ¦‚è§ˆ
    print_model_architecture(policy)
    
    policy.train()
    policy.to(device)
    
    # ============================================================
    # æ•°æ®åŠ è½½
    # ============================================================
    
    # delta_timestamps é…ç½®ï¼ˆAction Chunking æ ¸å¿ƒï¼‰
    delta_timestamps = {
        "action": make_delta_timestamps(cfg.action_delta_indices, dataset_metadata.fps),
    }
    # å¦‚æœæœ‰å›¾åƒç‰¹å¾ï¼Œæ·»åŠ å†å²å¸§
    delta_timestamps |= {
        k: make_delta_timestamps(cfg.observation_delta_indices, dataset_metadata.fps)
        for k in cfg.image_features
    }
    
    print(f"\nğŸ“‚ åŠ è½½æ•°æ®é›†...")
    # æ³¨æ„ï¼šRTX 5090 + PyTorch nightly éœ€è¦ç”¨ pyav åç«¯ï¼ˆtorchcodec ä¸å…¼å®¹ï¼‰
    dataset = LeRobotDataset(dataset_id, delta_timestamps=delta_timestamps, video_backend="pyav")
    print(f"   æ ·æœ¬æ•°: {len(dataset)}")
    
    # åˆ›å»º DataLoader
    dataloader = torch.utils.data.DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4,
        pin_memory=device.type != "cpu",
        drop_last=True,
    )
    
    # ============================================================
    # è®­ç»ƒå¾ªç¯
    # ============================================================
    
    optimizer = cfg.get_optimizer_preset().build(policy.parameters())
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ ({training_steps} æ­¥)...")
    print("-" * 50)
    
    step = 0
    done = False
    start_time = time.time()
    losses = []
    
    while not done:
        for batch in dataloader:
            batch = preprocessor(batch)
            
            # å°†æ•°æ®ç§»åˆ° GPU
            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
            
            # å‰å‘ä¼ æ’­
            loss, info = policy.forward(batch)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            
            losses.append(loss.item())
            
            if step % log_freq == 0:
                elapsed = time.time() - start_time
                avg_loss = sum(losses[-log_freq:]) / len(losses[-log_freq:])
                
                # è®¡ç®—é¢„ä¼°å‰©ä½™æ—¶é—´
                if step > 0:
                    steps_remaining = training_steps - step
                    speed = elapsed / step  # ç§’/æ­¥
                    eta_seconds = steps_remaining * speed
                    eta_min = int(eta_seconds // 60)
                    eta_sec = int(eta_seconds % 60)
                    eta_str = f" | ETA: {eta_min}m {eta_sec}s"
                else:
                    eta_str = ""
                
                print(f"Step {step:4d} | Loss: {loss.item():.4f} | Avg: {avg_loss:.4f} | Time: {elapsed:.1f}s{eta_str}")
                
                # æ˜¾ç¤ºæ˜¾å­˜ä½¿ç”¨
                if device.type == "cuda":
                    mem_used = torch.cuda.memory_allocated() / 1024**3
                    print(f"         | GPU Memory: {mem_used:.2f} GB")
            
            step += 1
            if step >= training_steps:
                done = True
                break
    
    # ============================================================
    # è®­ç»ƒå®Œæˆ
    # ============================================================
    
    total_time = time.time() - start_time
    print("-" * 50)
    print(f"âœ… è®­ç»ƒå®Œæˆ!")
    print(f"   æ€»æ­¥æ•°: {step}")
    print(f"   æ€»æ—¶é—´: {total_time:.1f}s")
    print(f"   å¹³å‡é€Ÿåº¦: {total_time/step*1000:.1f} ms/step")
    print(f"   æœ€ç»ˆ Loss: {losses[-1]:.4f}")
    
    # ä¿å­˜æ¨¡å‹
    print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹åˆ°: {output_directory}")
    policy.save_pretrained(output_directory)
    preprocessor.save_pretrained(output_directory)
    postprocessor.save_pretrained(output_directory)
    
    print("\nğŸ‰ Demo å®Œæˆï¼")
    print(f"   æ¨¡å‹è·¯å¾„: {output_directory.absolute()}")
    print(f"   å¯ç”¨äºæ¨ç†: ACTPolicy.from_pretrained('{output_directory}')")


if __name__ == "__main__":
    main()

